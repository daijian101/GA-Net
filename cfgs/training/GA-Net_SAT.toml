train = true
test = false
save_test_segmentation_map = true


user_path = '/data1/dj'
data_path = '${user_path}/data/bca'

is_ddp = false
gpus = ['0']
n_classes = 2

tissue_label = 'SAT'
region_label = 'SR'

start_unbalance_loss_epoch = 100
tissue_loss_ratio = 0.6
region_loss_ratio = 0.4

lr = 1e-2
epochs = 1000
batch_size = 12
n_iter_per_epoch = 250
val_batch_size = 50
val_interval = 10

checkpoint_saved_interval = 10

snapshot = '${user_path}/running/bca_${tissue_label}_GA-Net_test'
checkpoint = '/data1/dj/running/bca_SAT_GA-Net/checkpoint/checkpoint_60.pth'

# Accelerator
[cudnn]
benchmark = true
deterministic = false

# data transformer

[training_data_augments.spatial_transform]
# Spatial transform
patch_size = [512, 512]
patch_center_dist_from_border = 0
random_crop = false
p_elastic_defrom = 0
p_rotation = 0.2
rotation = [-3.1415926, 3.1415926]
p_scaling = 0.2
scaling = [0.7, 1.4]
p_synchronize_scaling_across_axes = 1

[training_data_augments.gaussian_noise_transform]
p = 0.1
noise_variance = [0, 0.1]
p_per_channel = 1
synchronize_channels = true

[training_data_augments.gaussian_blur_transform]
p = 0.2
blur_sigma = [0.5, 1.0]
synchronize_channels = true
synchronize_axes = false
p_per_channel = 0.5

[training_data_augments.brightness_transform]
p = 0.15
multiplier_range = [0.75, 1.25]
synchronize_channels = false
p_per_channel = 1

[training_data_augments.contrast_transform]
p = 0.15
contrast_range = [0.75, 1.25]
preserve_range = true
synchronize_channels = false
p_per_channel = 1

[training_data_augments.gamma_transform1]
p = 0.1
gamma = [0.7, 1.5]
p_invert_image = 1
synchronize_channels = false
p_per_channel = 1
p_retain_stats = 1

[training_data_augments.gamma_transform2]
p = 0.3
gamma = [0.7, 1.5]
p_invert_image = 0
synchronize_channels = false
p_per_channel = 1
p_retain_stats = 1

[dataset]
# dataset property file. This includes training, validation, and test samples, as well as the mean and std statistics
dataset_property_file = '${data_path}/dataset/${tissue_label}_dataset_properties.json'

# for training
[dataset.slice_sample_dir]
slice_dir = '${data_path}/json/slices'
image = '${slice_dir}/images'
SAT = '${slice_dir}/SAT'
SR = '${slice_dir}/SR'
VAT = '${slice_dir}/VAT'
IAM = '${slice_dir}/IAM'
SMT = '${slice_dir}/SMT'
SMR = '${slice_dir}/SMR'
Sk = '${slice_dir}/Sk'
Dphm = '${slice_dir}/Dphm'

# for validation
[dataset.volume_sample_dir]
volume_dir = '${data_path}/json/volume'
im0_dir = '${data_path}/cavass_data/images'
image = '${volume_dir}/images'
SAT = '${volume_dir}/SAT'
VAT = '${volume_dir}/VAT'
SMT = '${volume_dir}/SMT'
Sk = '${volume_dir}/Sk'
Dphm = '${volume_dir}/Dphm'